{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":["Ju2LsGHnbeDm","lJzXhRsFrgzm","XVQ7mzCteWP8","XYgjdNya5gV3","7qGjpmzuqBXV","Wetn3DmpewMA","_uzmVMytMXRY"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IPqoEeG1nh4e"},"source":["# U-Net binary cell segmentation\n","---\n","\n","<font size = 4>The corresponging **[GitHub repository](https://github.com/esgomezm/MU_Lux_CZ)**, developed by the authors of the paper. \n","\n","---\n","<font size = 4>**Please cite the original papers of the U-Net** "]},{"cell_type":"markdown","metadata":{"id":"MDxUcoM3oP8p"},"source":["##Give access to your accound in Drive"]},{"cell_type":"code","metadata":{"id":"oKpmutq1eTk2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623830513605,"user_tz":-120,"elapsed":35859,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"5f09aaa4-788f-490d-9510-28c1501372b2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57TeLyxSqHI2","executionInfo":{"status":"ok","timestamp":1623830513607,"user_tz":-120,"elapsed":31,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"34666bd7-c4de-4401-de2c-3af5deaa5bf9"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wed Jun 16 08:01:53 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GXfVlIuYqNF3","executionInfo":{"status":"ok","timestamp":1621254154956,"user_tz":-120,"elapsed":30974,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"7a5264ed-0cfc-4ba7-8d98-6a980868804c"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"\n","menu, and then select High-RAM in the Runtime shape dropdown. Then, \n","re-execute this cell.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KfKLDI-AgaHR"},"source":["## Install required libraries\n","<font size = 4>In case it returns \"restart session\" at the end fo the installation, please click it and start from the beginning."]},{"cell_type":"code","metadata":{"id":"7LiyePSEgoii","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623830622742,"user_tz":-120,"elapsed":105873,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"55664211-6540-4f0d-b7be-438eac73341a"},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Projectos/3D-PROTUCEL/Code\")\n","\n","!pip3 install -r MU_Lux_CZ/MU_Lux_CZ/requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from -r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 1)) (7.1.2)\n","Collecting opencv-python-headless\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/35/bfc76533f2274cd3da4e2cf255cd13ab9d7f6fc8990c06911e7f8fcc2130/opencv_python_headless-4.5.2.54-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)\n","\u001b[K     |████████████████████████████████| 38.2MB 1.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 4)) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 5)) (4.41.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 7)) (1.4.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from -r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 8)) (0.51.2)\n","Collecting tensorflow==2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/1a/0d79814736cfecc825ab8094b39648cc9c46af7af1bae839928acb73b4dd/tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2MB)\n","\u001b[K     |████████████████████████████████| 516.2MB 32kB/s \n","\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 10)) (0.16.2)\n","Collecting SimpleITK\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n","\u001b[K     |████████████████████████████████| 47.4MB 116kB/s \n","\u001b[?25hCollecting imreg_dft\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/68/57cf1e086e8cc8f75a647e8815d7cb5f9dc4686031687aad5e8e30980ce4/imreg_dft-2.0.0.tar.gz (101kB)\n","\u001b[K     |████████████████████████████████| 102kB 12.8MB/s \n","\u001b[?25hRequirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (from -r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 14)) (2.5.9)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 15)) (1.1.5)\n","Collecting plantcv\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/3b/db9a8d9acf60933d74ed88a707b23d55f60d4fbb4fddc14a8ea47e1a4195/plantcv-3.12.1-py3-none-any.whl (222kB)\n","\u001b[K     |████████████████████████████████| 225kB 53.7MB/s \n","\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 17)) (0.11.1)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 8)) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 8)) (57.0.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (0.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (3.3.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (0.36.2)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (1.1.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (0.12.0)\n","Collecting tensorboard<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 27.6MB/s \n","\u001b[?25hCollecting gast==0.3.3\n","  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (1.15.0)\n","Collecting tensorflow-estimator<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n","\u001b[K     |████████████████████████████████| 460kB 40.4MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (1.34.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (1.12.1)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (3.12.4)\n","Collecting h5py<2.11.0,>=2.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 41.1MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 10)) (2.5.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 10)) (1.1.1)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 10)) (7.1.2)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 10)) (3.2.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 10)) (2.4.1)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 14)) (1.1.0)\n","Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 14)) (1.4.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 15)) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 15)) (2.8.1)\n","Requirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (from plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (2.12.0)\n","Collecting opencv-python<4,>=3.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/56/df6df7724d85d9ad82d482adcebcc0e67cf3d7348ae5c44c27dc51c43bfc/opencv_python-3.4.14.53-cp37-cp37m-manylinux2014_x86_64.whl (48.9MB)\n","\u001b[K     |████████████████████████████████| 48.9MB 115kB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (0.22.2.post1)\n","Requirement already satisfied: plotnine in /usr/local/lib/python3.7/dist-packages (from plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (0.6.0)\n","Collecting dask-jobqueue\n","  Downloading https://files.pythonhosted.org/packages/22/4a/bf4ea9c12c825d0926899d9c08d1abc009ac0779c6b2476aa419a02de719/dask_jobqueue-0.7.2-py2.py3-none-any.whl\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (0.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (1.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (1.31.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (3.3.4)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 10)) (4.4.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 10)) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 10)) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 10)) (0.10.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (1.0.1)\n","Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (1.1.0)\n","Requirement already satisfied: mizani>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (0.6.0)\n","Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from plotnine->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (0.5.1)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (0.10.2)\n","Collecting distributed>=2.19\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/57/4ab1e5b6a4aee968ab7a808ca99fd85a4709c2e2b32bf6956cfd5e6c6c82/distributed-2021.6.0-py3-none-any.whl (715kB)\n","\u001b[K     |████████████████████████████████| 716kB 49.8MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (1.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (4.7.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (4.5.0)\n","Requirement already satisfied: palettable in /usr/local/lib/python3.7/dist-packages (from mizani>=0.6.0->plotnine->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (3.3.0)\n","Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (0.11.1)\n","Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (1.7.0)\n","Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (2.0.0)\n","Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (1.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (3.13)\n","Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (5.4.8)\n","Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (2.4.0)\n","Collecting cloudpickle>=1.5.0\n","  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n","Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from distributed>=2.19->dask-jobqueue->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (5.1.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (3.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 9)) (3.7.4.3)\n","Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.19->dask-jobqueue->plantcv->-r MU_Lux_CZ/MU_Lux_CZ/requirements.txt (line 16)) (1.0.1)\n","Building wheels for collected packages: imreg-dft\n","  Building wheel for imreg-dft (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imreg-dft: filename=imreg_dft-2.0.0-cp37-none-any.whl size=47202 sha256=4c20cad1bc60db924a384dca92f85dc7398bac9f51d6b402ebc99eaa650b1110\n","  Stored in directory: /root/.cache/pip/wheels/af/40/ca/1ef8f71ee679d463d7d73bf918a5807aa2b0e8e35cc59f5489\n","Successfully built imreg-dft\n","\u001b[31mERROR: distributed 2021.6.0 has requirement dask==2021.06.0, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[31mERROR: dask-jobqueue 0.7.2 has requirement dask>=2.19, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n","Installing collected packages: opencv-python-headless, tensorboard, gast, tensorflow-estimator, h5py, tensorflow, SimpleITK, imreg-dft, opencv-python, cloudpickle, distributed, dask-jobqueue, plantcv\n","  Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Found existing installation: tensorflow-estimator 2.5.0\n","    Uninstalling tensorflow-estimator-2.5.0:\n","      Successfully uninstalled tensorflow-estimator-2.5.0\n","  Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Found existing installation: tensorflow 2.5.0\n","    Uninstalling tensorflow-2.5.0:\n","      Successfully uninstalled tensorflow-2.5.0\n","  Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","  Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","  Found existing installation: distributed 1.25.3\n","    Uninstalling distributed-1.25.3:\n","      Successfully uninstalled distributed-1.25.3\n","Successfully installed SimpleITK-2.0.2 cloudpickle-1.6.0 dask-jobqueue-0.7.2 distributed-2021.6.0 gast-0.3.3 h5py-2.10.0 imreg-dft-2.0.0 opencv-python-3.4.14.53 opencv-python-headless-4.5.2.54 plantcv-3.12.1 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IM3i4ZJy5R8w"},"source":["# Run the training using a .json file that contains all the details"]},{"cell_type":"code","metadata":{"id":"JqrD2p5FULfB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623831537967,"user_tz":-120,"elapsed":8650,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"fbd0465a-e477-4700-dab0-d9265c308590"},"source":["!python MU_Lux_CZ/MU_Lux_CZ/train.py 'MU_Lux_CZ/MU_Lux_CZ/examples/experiments/config_mobilenet_lstm_tips_5.json' "],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'n_filters': 25, 'pools': 3, 'kernel_size': [3, 3], 'dilation_rate': 1, 'mobile_alpha': 0.35, 'time_windows': 5, 'lr': 0.0001, 'dropout': 0.05, 'activation': 'elu', 'last_activation': 'tanh', 'padding': 'same', 'kernel_initializer': 'glorot_uniform', 'lossfunction': 'sparse_cce', 'loss_tips': 'L1L2', 'metrics': 'accuracy', 'train_decoder_only': 0, 'category_weights': [1, 10]}\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","2021-06-16 08:18:51.739758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-06-16 08:18:51.753304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-16 08:18:51.753888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n","coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n","2021-06-16 08:18:51.754195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-06-16 08:18:51.755636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-06-16 08:18:51.757196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-06-16 08:18:51.757557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-06-16 08:18:51.759001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-06-16 08:18:51.759711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-06-16 08:18:51.762648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-06-16 08:18:51.762770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-16 08:18:51.763361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-16 08:18:51.763935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n","2021-06-16 08:18:51.764184: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2021-06-16 08:18:51.768886: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2000175000 Hz\n","2021-06-16 08:18:51.769073: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ad74e8cbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-06-16 08:18:51.769103: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-06-16 08:18:51.865771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-16 08:18:51.866655: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ad74e8ca00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-06-16 08:18:51.866690: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2021-06-16 08:18:51.866882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-16 08:18:51.867450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n","coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n","2021-06-16 08:18:51.867548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-06-16 08:18:51.867578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-06-16 08:18:51.867605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-06-16 08:18:51.867627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-06-16 08:18:51.867650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-06-16 08:18:51.867674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-06-16 08:18:51.867697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-06-16 08:18:51.867776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-16 08:18:51.868350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-16 08:18:51.868864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n","2021-06-16 08:18:51.868936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-06-16 08:18:51.870177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-06-16 08:18:51.870207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n","2021-06-16 08:18:51.870218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n","2021-06-16 08:18:51.870357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-16 08:18:51.870955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-16 08:18:51.871508: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-06-16 08:18:51.871553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15064 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_image (InputLayer)        [(None, None, None,  0                                            \n","__________________________________________________________________________________________________\n","time_distributed (TimeDistribut (None, None, None, N 56562       input_image[0][0]                \n","__________________________________________________________________________________________________\n","conv_lst_m2d_1 (ConvLSTM2D)     (None, None, None, 2 45100       time_distributed[0][0]           \n","__________________________________________________________________________________________________\n","conv_lst_m2d (ConvLSTM2D)       (None, None, None, 2 45100       time_distributed[0][0]           \n","__________________________________________________________________________________________________\n","tf_op_layer_ExpandDims_1 (Tenso [(None, 1, None, Non 0           conv_lst_m2d_1[0][0]             \n","__________________________________________________________________________________________________\n","tf_op_layer_ExpandDims (TensorF [(None, 1, None, Non 0           conv_lst_m2d[0][0]               \n","__________________________________________________________________________________________________\n","time_distributed_2 (TimeDistrib (None, 1, None, None 26          tf_op_layer_ExpandDims_1[0][0]   \n","__________________________________________________________________________________________________\n","time_distributed_1 (TimeDistrib (None, 1, None, None 52          tf_op_layer_ExpandDims[0][0]     \n","__________________________________________________________________________________________________\n","time_distributed_3 (TimeDistrib (None, 1, None, None 0           time_distributed_2[0][0]         \n","==================================================================================================\n","Total params: 146,840\n","Trainable params: 144,396\n","Non-trainable params: 2,444\n","__________________________________________________________________________________________________\n","U-Net with MobileNetV2 encoder and MobileDecoder with ConvLSTM2D for segmentation and tips detection.\n","Loading weights from /content/drive/MyDrive/BiiG/3D-PROTUCEL/SERVER-RESULTS/mobilenet_lstm_experiment_5/checkpoints/mobilenet_mobileunet_lstm_tips_00800.hdf5\n","Traceback (most recent call last):\n","  File \"MU_Lux_CZ/MU_Lux_CZ/train.py\", line 23, in <module>\n","    keras_model = build_model(config)\n","  File \"/content/drive/My Drive/Projectos/3D-PROTUCEL/Code/MU_Lux_CZ/MU_Lux_CZ/models/builder.py\", line 26, in build_model\n","    keras_model = build_mobilenet_mobileunet_lstm_multiple(config, model_kwargs)\n","  File \"/content/drive/My Drive/Projectos/3D-PROTUCEL/Code/MU_Lux_CZ/MU_Lux_CZ/models/builder.py\", line 191, in build_mobilenet_mobileunet_lstm_multiple\n","    keras_model.load_weights(config.train_pretrained_weights)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 250, in load_weights\n","    return super(Model, self).load_weights(filepath, by_name, skip_mismatch)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/network.py\", line 1259, in load_weights\n","    with h5py.File(filepath, 'r') as f:\n","  File \"/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\", line 408, in __init__\n","    swmr=swmr)\n","  File \"/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\", line 173, in make_fid\n","    fid = h5f.open(name, flags, fapl=fapl)\n","  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n","  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n","  File \"h5py/h5f.pyx\", line 88, in h5py.h5f.open\n","OSError: Unable to open file (unable to open file: name = '/content/drive/MyDrive/BiiG/3D-PROTUCEL/SERVER-RESULTS/mobilenet_lstm_experiment_5/checkpoints/mobilenet_mobileunet_lstm_tips_00800.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0-hZZ0ZqeNKe"},"source":["!python MU_Lux_CZ/MU_Lux_CZ/test.py 'MU_Lux_CZ/mobilenet_lstm_experiment_decoder_2/config_mobilenet_lstm_tips_only_decoder_2.json' "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B77ftaH0zIja"},"source":["# %load_ext tensorboard\n","# %reload_ext tensorboard\n","# import tensorflow as tf\n","# %tensorboard --logdir '/content/drive/My Drive/Projectos/3D-PROTUCEL/Code/MU_Lux_CZ/SERVER-RESULTS/mobilenet_lstm_tips_onlydecoder_praful_v02_colab_keep322/logs/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mgK519_KhxLW"},"source":["# Run test"]},{"cell_type":"code","metadata":{"id":"e9yfdbiBMhxo"},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Projectos/3D-PROTUCEL/Code\")\n","# !python MU_Lux_CZ/MU_Lux_CZ/train.py 'MU_Lux_CZ/MU_Lux_CZ/examples/config_mobilenet_mobileunet_lstm_tips_large.json'\n","!python MU_Lux_CZ/MU_Lux_CZ/test.py 'MU_Lux_CZ/MU_Lux_CZ/examples/config_mobilenet_mobileunet_lstm_tips_large.json'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ju2LsGHnbeDm"},"source":["# Run image processing\n","\n","Load a model from a configuration file. Load a specified pretrained weights and process some images"]},{"cell_type":"code","metadata":{"id":"CmKBj7zfZcXo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614335626956,"user_tz":-60,"elapsed":378,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"1a05c16b-8f19-4c27-9427-301085a0c113"},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Projectos/3D-PROTUCEL/Code/MU_Lux_CZ/MU_Lux_CZ\")\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08759594.pdf\t    inference_new_videos.py\t    README.md\n","additional_scripts  internals\t\t\t    requirements.txt\n","ctc_evaluation.py   models\t\t\t    RESULTS.md\n","data_generators     MU-Lux-CZ.pdf\t\t    test.py\n","EvaluationSoftware  notebooks\t\t\t    train.py\n","examples\t    prueba_inference_new_videos.py  utils\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OeiZxwvXZIg3"},"source":["from utils.read_config import Dict2Obj\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from utils.utils import read_input_image, read_input_videos\n","\n","PATH2CONFIG = 'examples/config_lstm_tips_detection.json'\n","config = Dict2Obj(PATH2CONFIG)\n","\n","from tensorflow.keras.optimizers import Adam\n","# Define a Keras model using a predefined function\n","model_kwargs = {k[len('model_'):]: v for (k,v) in vars(config).items() if k.startswith('model_')}\n","from models.lstm import UNetLSTM_tips\n","\n","keras_model = UNetLSTM_tips(input_shape=(1,960,960,1), **model_kwargs)\n","trained_weights = '/content/drive/MyDrive/Projectos/3D-PROTUCEL/Code/MU_Lux_CZ/lstm_tips_results/checkpoints/lstm_unet00020.hdf5'\n","keras_model.load_weights(trained_weights)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LUP8JClfyDbU"},"source":["import matplotlib.pyplot as plt\n","print(keras_model.loss)\n","output_dir = os.path.join(config.OUTPUTPATH, \"test_output\")\n","\n","\n","model_prediction_lstm(config.TESTPATH, output_dir, config.PATH2VIDEOS, keras_model,\n","                      config.model_time_windows, [960, 960], \n","                      config.newinfer_padding)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lJzXhRsFrgzm"},"source":["## Visualize some results after the training\n","Note that the output of a model trained for sparse categorical cross entropy needs are the logits rather than the output of an activation function. Hence a softmax (tf.argmax) or a sigmoid (tf.sigmoid) function needs to be applied.\n","\n","Remove the activation operations to visualize the remaining cases for which the inference is given directly in the output."]},{"cell_type":"code","metadata":{"id":"ekpG4n-yLS7R"},"source":["from utils.utils import read_input_image\n","\n","im = read_input_image(\"/content/drive/My Drive/Projectos/3D-PROTUCEL/Code/data/test/stack2im/inputs/raw_098.tif\")\n","im = im[200:712,400:912]\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(10,10))\n","plt.imshow(im)\n","plt.show()\n","\n","im = im.reshape((1,512,512))\n","\n","pred = keras_model.predict(im)\n","import tensorflow as tf\n","pred_1 = tf.sigmoid(pred)\n","\n","plt.figure(figsize=(10,10))\n","plt.imshow(pred_1[0,:,:,0])\n","plt.colorbar()\n","plt.show()\n","\n","plt.figure(figsize=(10,10))\n","plt.imshow(pred_1[0,:,:,1])\n","plt.colorbar()\n","plt.show()\n","\n","plt.figure(figsize=(10,10))\n","plt.imshow(pred_1[0,:,:,2])\n","plt.colorbar()\n","plt.show()\n","\n","pred_2 = tf.argmax(pred, axis=-1)\n","plt.figure(figsize=(10,10))\n","plt.imshow(pred_2[0])\n","plt.colorbar()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XVQ7mzCteWP8"},"source":["## Run inference through a python function as a command line"]},{"cell_type":"code","metadata":{"id":"gGyqYnXubdvR"},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Projectos/3D-PROTUCEL/Code\")\n","!python MU_Lux_CZ/MU_Lux_CZ/test.py 'MU_Lux_CZ/MU_Lux_CZ/examples/config4dirve_weighted_cce_001.json'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6A6WyZ2b8Qm"},"source":["import SimpleITK as sitk\n","im = sitk.ReadImage('../keypoints_001/test_output/raw_276.tif')\n","im = sitk.GetArrayFromImage(im)\n","frame = im[-1]\n","im = im[:-1]\n","im.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IK42Gu-PuT9o"},"source":["# Run each of the steps in train.py separately"]},{"cell_type":"markdown","metadata":{"id":"muOqZOcbpv4W"},"source":["Correct the ocation to the directory where the repository was cloned. "]},{"cell_type":"code","metadata":{"id":"44mQFcfdurHu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614787261465,"user_tz":-60,"elapsed":563,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"35701364-2e94-4b25-f889-929e48bad595"},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Projectos/3D-PROTUCEL/Code/MU_Lux_CZ/CellProtrusionTimeDLPhC\")\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08759594.pdf\t    inference_new_videos.py\t    README.md\n","additional_scripts  internals\t\t\t    requirements.txt\n","ctc_evaluation.py   models\t\t\t    RESULTS.md\n","data_generators     MU-Lux-CZ.pdf\t\t    test.py\n","EvaluationSoftware  notebooks\t\t\t    train.py\n","examples\t    prueba_inference_new_videos.py  utils\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XYgjdNya5gV3"},"source":["## Check data generator"]},{"cell_type":"code","metadata":{"id":"DarmS28h5ijW"},"source":["from utils.read_config import Dict2Obj\n","PATH2CONFIG = 'examples/config_mobilenet_lstm_external_decoder_v05.json'\n","config = Dict2Obj(PATH2CONFIG)\n","# from data_generators.initializers import training_videos_tips, training_videos\n","training_generator = training_videos(config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1_TNkjpEeoY"},"source":["del training_generator, train_x, train_y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1XUrK6ml1TPcM31f8CwlWy6C4rtHVJ-Gg"},"id":"T4I4_3wA6d1B","executionInfo":{"status":"ok","timestamp":1614338428603,"user_tz":-60,"elapsed":152687,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"c6cbb244-f943-4659-8d0b-66953c151db0"},"source":[" for i in range(55):\n","    train_x, train_y = training_generator.__getitem__(i)\n","\n","    for k in range(train_x.shape[0]):\n","      plt.figure(figsize=(25,5))\n","      for i in range(train_x.shape[1]):\n","        plt.subplot(1,train_x.shape[1], i+1)\n","        plt.imshow(train_x[k, i,:,:,0])\n","      plt.show()\n","      if len(train_y)==2:\n","        plt.figure()\n","        plt.subplot(1,2,1)\n","        plt.imshow(train_y[0][k, 0,...,0])\n","        plt.subplot(1,2,2)\n","        plt.imshow(train_y[1][k, 0,...,0])\n","        plt.colorbar()\n","        plt.show()\n","\n","      else:\n","        plt.figure()\n","        plt.imshow(train_y[k, 0,...,0])\n","        plt.colorbar()\n","        plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"7qGjpmzuqBXV"},"source":["## Prepare for the training. Read some validation data and display it\n","*   Read the configuration file (.json)\n","*   Call the data generator for the training\n","*   Create a small set from the test images to use it as a validation set."]},{"cell_type":"code","metadata":{"id":"TWikjJ4RuZuW"},"source":["from utils.read_config import Dict2Obj\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","# Read the configuration file with all the metadata and information about the training.\n","# PATH2CONFIG = 'examples/config4dirve_weighted_cce_001.json'\n","PATH2CONFIG = 'examples/config_mobilenet_lstm_external_pretrainedv02_v01.json'\n","config = Dict2Obj(PATH2CONFIG)\n","\n","# Load training data using training_generator\n","# from data_generators.initializers import training_contours, test_shots_contours\n","# training_generator = training_contours(config)\n","from data_generators.initializers import training_videos_tips, training_videos\n","# training_generator = training_videos_tips(config)\n","training_generator = training_videos(config)\n","# val_x, val_y = test_shots_contours(config)\n","train_x, train_y = training_generator.__getitem__(0)\n","# Display one example of the validation dataset.\n","# print(\"Example of an image and its ground truth from the validation set\")\n","\n","# plt.figure(figsize=(10,10))\n","# plt.subplot(1,2,1)\n","# plt.imshow(val_x[2,:,:,0])\n","# plt.subplot(1,2,2)\n","# plt.imshow(val_y[2,:,:,0])\n","# plt.show()\n","\n","print(train_x.shape)\n","print(len(train_y))\n","# print(train_y[0].shape)\n","# print(train_y[1].shape)\n","\n","\n","for k in range(train_x.shape[0]):\n","  plt.figure(figsize=(25,5))\n","  for i in range(train_x.shape[1]):\n","    plt.subplot(1,train_x.shape[1], i+1)\n","    plt.imshow(train_x[k, i,:,:,0])\n","  plt.show()\n","  if len(train_y)==2:\n","    plt.figure()\n","    plt.subplot(1,2,1)\n","    plt.imshow(train_y[0][k, 0,...,0])\n","    plt.subplot(1,2,2)\n","    plt.imshow(train_y[1][k, 0,...,0])\n","    plt.colorbar()\n","    plt.show()\n","\n","  else:\n","    plt.figure()\n","    plt.imshow(train_y[k, 0,...,0])\n","    plt.colorbar()\n","    plt.show()\n","\n","\n","\n","from data_generators.initializers import test_videos_tips, test_videos\n","\n","# val_x, val_y = test_videos_tips(config)\n","val_x, val_y = test_videos(config)\n","print(val_x.shape)\n","print(len(val_y))\n","# print(val_y[0].shape)\n","# print(val_y[1].shape)\n","for k in range(val_x.shape[0]):\n","\n","    plt.figure(figsize=(25,5))\n","    for i in range(val_x.shape[1]):\n","      plt.subplot(1,val_x.shape[1], i+1)\n","      plt.imshow(val_x[k, i,:,:,0])\n","    plt.show()\n","    if len(val_y)==2:\n","      plt.figure()\n","      plt.subplot(1,2,1)\n","      plt.imshow(val_y[0][k, 0,...,0])\n","      plt.subplot(1,2,2)\n","      plt.imshow(val_y[1][k, 0,...,0])\n","      plt.colorbar()\n","      plt.show()\n","    else:\n","      plt.figure()\n","      plt.imshow(val_y[k, 0,...,0])\n","      plt.colorbar()\n","      plt.show()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wetn3DmpewMA"},"source":["## Dislpay how L1L2 loss function works"]},{"cell_type":"code","metadata":{"id":"0B4lZ0R53hxe"},"source":["from internals.metrics import matlab_style_gauss2D, L1L2loss\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import losses\n","# small sigma penalizes false positives\n","# large sigma penalizes false negatives\n","# centered sigma with a window of (20,20), is adjusted to both false negative and positives\n","\n","psf_heatmap = matlab_style_gauss2D(shape=(15, 15), sigma=4) \n","gfilter = tf.reshape(psf_heatmap, [1, 15, 15, 1, 1])\n","# L1L2loss((), gfilter, strides=(1, 1, 1))\n","plt.imshow(np.array(gfilter[0,...,0,0]))\n","plt.show()\n","\n","strides=(1, 1, 1)\n","heatmap_pred = K.conv3d(A, gfilter, strides=strides, padding='same')\n","\n","plt.imshow(heatmap_pred[0,0,...,0])\n","plt.colorbar()\n","plt.title('heat map pred')\n","plt.show()\n","\n","# heatmaps MSE\n","loss_heatmaps = losses.mean_squared_error(B,heatmap_pred)\n","\n","plt.imshow(loss_heatmaps[0,0])\n","plt.colorbar()\n","plt.title('loss mse heat maps')\n","plt.show()\n","\n","# l1 on the predicted spikes\n","loss_spikes = losses.mean_absolute_error(A,tf.zeros(A.shape))\n","\n","plt.imshow(loss_spikes[0,0])\n","plt.colorbar()\n","plt.title('loss absolute error prediction')\n","plt.show()\n","\n","R = loss_heatmaps + loss_spikes\n","plt.imshow(R[0,0])\n","plt.colorbar()\n","plt.title('sum')\n","plt.show()    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lvHNgKFpq2FX"},"source":["## Load the model and run the training"]},{"cell_type":"code","metadata":{"id":"JkErm2VCrHul","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614787321359,"user_tz":-60,"elapsed":57834,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"8d310a91-ba8d-4ff6-f3cb-7c479fa417f0"},"source":["import os\n","import sys\n","from internals.callbacks import initiate_callbacks, ImagesTensorboardCallback\n","from utils.read_config import Dict2Obj\n","from internals.build_processed_videos import build_videos_CTC\n","from internals.tiling_strategy import model_prediction, model_prediction_lstm\n","from data_generators.build_data import generate_data\n","\n","# Read the configuration file with all the metadata and information about the training.\n","PATH2CONFIG = 'examples/config_mobilenet_lstm_external_v08_keepfrombest.json'\n","# PATH2CONFIG = sys.argv[1]\n","\n","# PATH2CONFIG = 'trained_config/config_docker_local.json'\n","\n","config = Dict2Obj(PATH2CONFIG)\n","training_generator, val_x, val_y = generate_data(config)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Creating validation data...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sm6H-XqRfet-","executionInfo":{"status":"ok","timestamp":1614787341489,"user_tz":-60,"elapsed":20111,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"47e8f244-5e64-4c3d-9bdc-d2d74f3dc782"},"source":["from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, UpSampling2D, Activation\n","from tensorflow.keras.layers import Concatenate, SeparableConv2D, Dropout, TimeDistributed, ConvLSTM2D\n","from tensorflow.keras.applications import MobileNetV2\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError\n","from tensorflow.keras.optimizers import Adam\n","from models.lstm import jaccard_sparse3D\n","\n","alpha = config.model_mobile_alpha\n","n_filters = config.model_n_filters\n","dilation_rate = config.model_dilation_rate\n","activation = config.model_activation\n","dropout = config.model_dropout\n","\n","#---------------------------------------------\n","def DepthwiseSeparableBlock2D(n_filters=16,\n","                              kernel=(3, 3),\n","                              strides=(1, 1),\n","                              dilation_rate=1,\n","                              activation=\"relu\",\n","                              last=False,\n","                              dropout=None,\n","                              n_layers=2):\n","    \"\"\"Convolutional layers\n","    Depthwise separable 2D Convolutions => BatchNormalization => Activation => Dropout (optional)\n","    Args:\n","        n_filters: number of filters\n","        kernel: filter size\n","        strides: strides for downsampling\n","        dilation_rate: dilated convolutions for increasing the receptive field.\n","        activation: activation function of each convolutional block\n","        dropout: If True, adds the dropout layer\n","        last: If true, the last convolutional block is named as last separable to identify it.\n","        n_layers: number of convolutional layers in block\n","    Returns:\n","    Convolutional block\n","    \"\"\"\n","    result = tf.keras.Sequential()\n","    for i in range(n_layers):\n","        if last and i == n_layers:\n","            result.add(SeparableConv2D(n_filters, kernel, strides=strides, dilation_rate=dilation_rate, padding=\"same\",\n","                                       name='last_separable_2d'))\n","        else:\n","            result.add(SeparableConv2D(n_filters, kernel, strides=strides, dilation_rate=dilation_rate, padding=\"same\"))\n","        result.add(BatchNormalization())\n","        result.add(Activation(activation))\n","        if dropout is not None and dropout > 0:\n","            result.add(Dropout(dropout))\n","\n","    return result\n","\n","\n","def upsample(**kwargs):\n","    \"\"\"Upsamples an input.\n","    Depthwise separable block (2 layers) => Depthwise separable block (2 layers) => UpSampling\n","    Returns:\n","    Upsample Sequential Model\n","    \"\"\"\n","    result = DepthwiseSeparableBlock2D(**kwargs)\n","    result.add(UpSampling2D((2, 2)))\n","    return result\n","\n","\n","def mobile_encoder(alpha, input_shape=(None, None, 3)):\n","    inputs=Input(shape=input_shape)\n","    base_model = tf.keras.applications.MobileNetV2(input_tensor=inputs, weights=\"imagenet\", include_top=False,\n","                                                   alpha=alpha)\n","    # Use the activations of these layers\n","    layer_names = [\n","        'block_1_expand_relu',  # 64x64\n","        'block_3_expand_relu',  # 32x32\n","        'block_6_expand_relu',  # 16x16\n","        'block_13_expand_relu',  # 8x8\n","        'block_16_project',  # 4x4\n","    ]\n","    layers = [base_model.get_layer(name).output for name in layer_names]\n","    # Create the feature extraction model\n","    encoder = tf.keras.Model(inputs=base_model.input, outputs=layers)\n","    return encoder\n","\n","def mobile_decoder(depth, n_filters, **kwargs):\n","    decoder = []\n","    for i in reversed(range(depth)):\n","        if i == depth-1:\n","            decoder.append(upsample(n_filters=n_filters * (2 ** i), last=True, **kwargs))\n","        else:\n","            decoder.append(upsample(n_filters=n_filters * (2 ** i), **kwargs))\n","    return decoder\n","\n","#---------------------------------------------\n","# Input to the encoder\n","inputs = Input(shape=(None, None, 1), name=\"input_image\")\n","_inputs = Concatenate(axis=-1, name=\"rgb_input\")([inputs, inputs, inputs])  ## MobileNet expects RGB images\n","\n","# Load the encoder model\n","encoder = mobile_encoder(alpha)\n","encoder.trainable = False\n","# Downsampling through the model and skip connections\n","skips = encoder(_inputs)\n","x = skips[-1]\n","skips = reversed(skips[:-1])\n","# Load model decoder\n","up_stack = mobile_decoder(len(encoder.output), n_filters, dilation_rate=dilation_rate,\n","                            activation=activation, dropout=dropout)\n","# Upsampling and establishing the skip connections\n","for up, skip in zip(up_stack, skips):\n","    x = up(x)\n","    x = Concatenate()([x, skip])\n","x = UpSampling2D((2, 2), name='last_upsampling')(x)\n","# Generate the last layers for the segmentation.\n","last_layer = DepthwiseSeparableBlock2D(n_filters, kernel=(3, 3), dilation_rate=dilation_rate,\n","                                        activation=activation, last=True)\n","seg = last_layer(x)\n","# seg = Conv2D(2, (1, 1), padding=\"same\", name='slog')(seg)\n","base_model = Model(inputs=inputs, outputs=seg)\n","#---------------------------------------------\n","\n","\n","\n","\n","inputs = Input(shape=(None, None, None, 1), name=\"input_image\")\n","# mobileunet = MobileNetV2_MobileUNet_base(n_filters=n_filters, activation=activation, dilation_rate=dilation_rate,\n","#                                     alpha=alpha, dropout=dropout, train_decoder_only=train_decoder_only)\n","# base_model = Model(mobileunet.input, mobileunet.get_layer('last_separable_2d').output)\n","# base_model = Model(mobileunet.input, mobileunet.get_layer(index=-2).output)\n","x = TimeDistributed(base_model)(inputs)\n","x = ConvLSTM2D(filters=n_filters, kernel_size=(3, 3)\n","                , padding='same'\n","                , data_format='channels_last'\n","                , dilation_rate=dilation_rate\n","                , activation=activation\n","                , return_sequences=False)(x)  # channels_last: (samples, timesteps, new_rows, new_cols, filters)\n","# seg = ConvLSTM2D(filters=2, kernel_size=(1, 1)\n","#                , padding='same'\n","#                , data_format='channels_last'\n","#                , dilation_rate=dilation_rate\n","#                , activation=None\n","#                , return_sequences=False\n","#                , name='slog')(x)  # channels_last: (samples, new_rows, new_cols, filters)\n","x = tf.expand_dims(x, axis=1)\n","seg = TimeDistributed(Conv2D(filters=2, kernel_size=(1, 1), padding=\"same\", activation=None, name='slog'))(x)\n","\n","model = Model(inputs=inputs, outputs=seg)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3i8wRtV4hkIW","executionInfo":{"status":"ok","timestamp":1614787440880,"user_tz":-60,"elapsed":703,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"b496d27c-2d07-4ce6-de16-b665d2c3752d"},"source":["# model.summary()\n","model.compile(optimizer=Adam(learning_rate=0.0001, name='adam'),\n","                  loss=SparseCategoricalCrossentropy(from_logits=True),\n","                  metrics=[jaccard_sparse3D, \"accuracy\"])\n","print('Loading weights from {}'.format(config.train_pretrained_weights))\n","model.load_weights(config.train_pretrained_weights)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading weights from /content/drive/My Drive/Projectos/3D-PROTUCEL/Code/MU_Lux_CZ/mobilenet_lstm_external_onlydecoder_v08_keepfrombest_keepfromlast/checkpoints/weights_best.hdf5\n","Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_image (InputLayer)     [(None, None, None, None, 0         \n","_________________________________________________________________\n","time_distributed (TimeDistri (None, None, None, None,  472000    \n","_________________________________________________________________\n","conv_lst_m2d (ConvLSTM2D)    (None, None, None, 16)    18496     \n","_________________________________________________________________\n","tf_op_layer_ExpandDims (Tens [(None, 1, None, None, 16 0         \n","_________________________________________________________________\n","time_distributed_1 (TimeDist (None, 1, None, None, 2)  34        \n","=================================================================\n","Total params: 490,530\n","Trainable params: 227,266\n","Non-trainable params: 263,264\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M7UvvbCHduO6"},"source":["import os\n","import sys\n","from internals.callbacks import initiate_callbacks, ImagesTensorboardCallback\n","\n","# Define callbacks and load pretrained weights\n","# ----------------------------------------------\n","Itb = ImagesTensorboardCallback(val_x, val_y, os.path.join(config.OUTPUTPATH, 'logs/tmp/'), n_images=10, step=20)\n","if config.train_pretrained_weights != \"None\":\n","    last_epoch = config.train_pretrained_weights\n","    if last_epoch.__contains__('/'):\n","        last_epoch = last_epoch.split('/')[-1]\n","    last_epoch = last_epoch.split('.')[0]\n","    callbacks = initiate_callbacks(config, model, last_epoch=last_epoch)\n","    # pretrained_weights = config.cnn_name + \"{epoch:0>5}.hdf5\".format(epoch=config.train_pretrained_weights)\n","    # keras_model.load_weights(os.path.join(config.OUTPUTPATH, 'checkpoints', pretrained_weights))\n","    # print('Loading weights from {}'.format(config.train_pretrained_weights))\n","    # keras_model.load_weights(config.train_pretrained_weights)\n","else:\n","    callbacks = initiate_callbacks(config, model)\n","callbacks.append(Itb)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qqe8z2gTp4hu"},"source":["model.trainable=True\n","model.fit(training_generator,\n","                validation_data=(val_x, val_y),\n","                epochs=150,\n","                validation_batch_size=config.datagen_batch_size,\n","                callbacks=callbacks)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yC1pUI6n1cY8"},"source":["model.save_weights(os.path.join(config.OUTPUTPATH, 'checkpoints', config.cnn_name + 'last.hdf5'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2f5LtEJ8xHcX"},"source":["from internals.callbacks import initiate_callbacks\n","from tensorflow.keras.optimizers import Adam\n","from utils.read_config import Dict2Obj\n","from models.builder import build_model\n","\n","# Define a Keras model using a predefined function\n","PATH2CONFIG = 'examples/config_lstm_tips_detection.json'\n","config = Dict2Obj(PATH2CONFIG)\n","keras_model = build_model(config)\n","\n","model_kwargs = {k[len('model_'):]: v for (k,v) in vars(config).items() if k.startswith('model_')}\n","# from models.unet import categorical_unet_fc_dil\n","# keras_model = categorical_unet_fc_dil(**model_kwargs)\n","\n","from models.lstm import UNetLSTM_tips\n","mi = config.datagen_dim_size[0]\n","ni = config.datagen_dim_size[1]\n","input_shape = (1, mi, ni, 1)\n","keras_model = UNetLSTM_tips(input_shape=input_shape, **model_kwargs)\n","\n","# config.train_pretrained_weights = 50\n","# config.OUTPUTPATH = '../externaldata_contours_allconv_001'\n","# Load pretrained weights\n","# if config.train_pretrained_weights != \"None\":\n","#     # Set desired callbacks\n","#     callbacks = initiate_callbacks(config, keras_model, last_epoch=config.train_pretrained_weights)\n","#     pretrained_weights = config.cnn_name + \"{epoch:0>5}.hdf5\".format(epoch=config.train_pretrained_weights)\n","#     keras_model.load_weights(os.path.join(config.OUTPUTPATH, 'checkpoints', pretrained_weights))\n","# else:\n","#     # Set desired callbacks\n","#     callbacks = initiate_callbacks(config, keras_model)\n","\n","print(keras_model.loss)\n","# keras_model.fit(training_generator, validation_data = (val_x, val_y), batch_size = 10, epochs=config.train_max_epochs, callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_uzmVMytMXRY"},"source":["# Some random code"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NYGeGVSEoYL8","executionInfo":{"status":"ok","timestamp":1613827885966,"user_tz":-60,"elapsed":671,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"7712ce51-b7e1-46a7-af05-498154c561ac"},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Projectos/3D-PROTUCEL/Code/MU_Lux_CZ/MU_Lux_CZ\")\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08759594.pdf\t    EvaluationSoftware\tMU-Lux-CZ.pdf\t  RESULTS.md\n","additional_scripts  examples\t\tnotebooks\t  test.py\n","ctc_evaluation.py   internals\t\tREADME.md\t  train.py\n","data_generators     models\t\trequirements.txt  utils\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GdXhZ4ZvoglG"},"source":["from models.lstm import jaccard_sparse3D\n","from models.mobilenets import DepthwiseSeparableBlock2D, upsample, mobile_decoder\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Concatenate, SeparableConv2D, ConvLSTM2D, \\\n","    TimeDistributed\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import MobileNetV2\n","\n","\n","def mobile_encoder(alpha, input_shape=(None, None, 3)):\n","    inputs=Input(shape=input_shape)\n","    base_model = tf.keras.applications.MobileNetV2(input_tensor=inputs, weights=\"imagenet\", include_top=False,\n","                                                   alpha=alpha)\n","    # Use the activations of these layers\n","    layer_names = [\n","        'block_1_expand_relu',  # 64x64\n","        'block_3_expand_relu',  # 32x32\n","        'block_6_expand_relu',  # 16x16\n","        'block_13_expand_relu',  # 8x8\n","        'block_16_project',  # 4x4\n","    ]\n","    layers = [base_model.get_layer(name).output for name in layer_names]\n","    # Create the feature extraction model\n","    encoder = tf.keras.Model(inputs=base_model.input, outputs=layers)\n","    return encoder\n","\n","def MobileNetV2_MobileUNet_base(n_filters=32, activation='relu', dilation_rate=1, alpha=0.35, dropout=None,\n","                           train_decoder_only=False):\n","    # Input to the encoder\n","    inputs = Input(shape=(None, None, 1), name=\"input_image\")\n","    _inputs = Concatenate(axis=-1, name=\"rgb_input\")([inputs, inputs, inputs])  ## MobileNet expects RGB images\n","\n","    # Load the encoder model\n","    encoder = mobile_encoder(alpha)\n","    if train_decoder_only:\n","        encoder.trainable = False\n","    else:\n","        encoder.trainable = True\n","\n","    # Downsampling through the model and skip connections\n","    skips = encoder(_inputs)\n","    x = skips[-1]\n","    skips = reversed(skips[:-1])\n","\n","    # Load model decoder\n","    up_stack = mobile_decoder(len(encoder.output), n_filters, dilation_rate=dilation_rate,\n","                               activation=activation, dropout=dropout)\n","\n","    # Upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        x = Concatenate()([x, skip])\n","    x = UpSampling2D((2, 2), name='last_upsampling')(x)\n","\n","    # Generate the last layers for the segmentation.\n","    last_layer = DepthwiseSeparableBlock2D(n_filters, kernel=(3, 3), dilation_rate=dilation_rate,\n","                                           activation=activation, last=True)\n","    seg = last_layer(x)\n","    seg = Conv2D(2, (1, 1), padding=\"same\", name='slog')(seg)\n","\n","    model = Model(inputs=inputs, outputs=seg)\n","    return model\n","\n","\n","def Recursive_MobileNetV2_MobileUnet_base(n_filters=32, activation='relu', dilation_rate=1, alpha=0.35, dropout=None,\n","                            train_decoder_only=False):\n","    inputs = Input(shape=(None, None, None, 1), name=\"input_image\")\n","    mobileunet = MobileNetV2_MobileUNet_base(n_filters=n_filters, activation=activation, dilation_rate=dilation_rate,\n","                                        alpha=alpha, dropout=dropout, train_decoder_only=train_decoder_only)\n","    # base_model = Model(mobileunet.input, mobileunet.get_layer('last_separable_2d').output)\n","    base_model = Model(mobileunet.input, mobileunet.get_layer(index=-2).output)\n","    x = TimeDistributed(base_model)(inputs)\n","    x = ConvLSTM2D(filters=n_filters, kernel_size=(3, 3)\n","                   , padding='same'\n","                   , data_format='channels_last'\n","                   , dilation_rate=dilation_rate\n","                   , activation=activation\n","                   , return_sequences=False)(x)  # channels_last: (samples, timesteps, new_rows, new_cols, filters)\n","    # seg = ConvLSTM2D(filters=2, kernel_size=(1, 1)\n","    #                , padding='same'\n","    #                , data_format='channels_last'\n","    #                , dilation_rate=dilation_rate\n","    #                , activation=None\n","    #                , return_sequences=False\n","    #                , name='slog')(x)  # channels_last: (samples, new_rows, new_cols, filters)\n","    x = tf.expand_dims(x, axis=1)\n","    seg = TimeDistributed(Conv2D(filters=2, kernel_size=(1, 1), padding=\"same\", activation=None, name='slog'))(x)\n","\n","    model = Model(inputs=inputs, outputs=seg)\n","    return model\n","\n","def Recursive_MobileNetV2_MobileUnet_compile(model, lr=0.001):\n","    model.compile(optimizer=Adam(learning_rate=lr, name='adam'),\n","                  loss=SparseCategoricalCrossentropy(from_logits=True),\n","                  metrics=[jaccard_sparse3D, \"accuracy\"])\n","    model.summary()\n","    print('U-Net with MobileNetV2 encoder and MobileDecoder with ConvLSTM2D for segmentation.')\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qVVXvPQ2pIEG","executionInfo":{"status":"ok","timestamp":1613828268702,"user_tz":-60,"elapsed":8684,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"2524b09c-3c0b-463e-a667-1d03b2452687"},"source":["unet = Recursive_MobileNetV2_MobileUnet_base(n_filters=8,train_decoder_only=True)\n","unet.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cHmUkzCUpPKv","executionInfo":{"status":"ok","timestamp":1613828273629,"user_tz":-60,"elapsed":424,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"6583339f-640d-47fd-bed3-252f7b599633"},"source":["import numpy as np\n","A = np.random.random((1,5,512,512,1))\n","B = np.random.random((1,1,512,512,1))\n","print(A.shape)\n","print(B.shape)\n","unet(A)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1, 5, 512, 512, 1)\n","(1, 1, 512, 512, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jgAuTNxkoxHa","executionInfo":{"status":"ok","timestamp":1613828436825,"user_tz":-60,"elapsed":12487,"user":{"displayName":"ESTIBALIZ GOMEZ DE MARISCAL","photoUrl":"","userId":"04592796515262324641"}},"outputId":"40556a3c-361c-4510-dba6-195617f5ba6f"},"source":["A = np.random.random((20,5,512,512,1))\n","B = np.random.random((20,1,512,512,1))\n","\n","unet = Recursive_MobileNetV2_MobileUnet_compile(unet, lr=0.001)\n","\n","unet.fit(x=A, y=B, batch_size=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_image (InputLayer)     [(None, None, None, None, 0         \n","_________________________________________________________________\n","time_distributed_2 (TimeDist (None, None, None, None,  336168    \n","_________________________________________________________________\n","conv_lst_m2d_1 (ConvLSTM2D)  (None, None, None, 8)     4640      \n","_________________________________________________________________\n","tf_op_layer_ExpandDims_1 (Te [(None, 1, None, None, 8) 0         \n","_________________________________________________________________\n","time_distributed_3 (TimeDist (None, 1, None, None, 2)  18        \n","=================================================================\n","Total params: 340,826\n","Trainable params: 78,554\n","Non-trainable params: 262,272\n","_________________________________________________________________\n","U-Net with MobileNetV2 encoder and MobileDecoder with ConvLSTM2D for segmentation.\n","20/20 [==============================] - 5s 252ms/step - loss: 0.3937 - jaccard_sparse3D: 0.0000e+00 - accuracy: 0.0000e+00\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f9d6a89acc0>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"ypdtNTAGqnGe"},"source":[""],"execution_count":null,"outputs":[]}]}